import argparse

import streamlit as st
import torch
from detect import detect, source_code
# from detect_api import detectapi
from PIL import Image
from io import *
import glob
from datetime import datetime
import os
import wget
import time

## CFG
cfg_model_path = "best.pt"

cfg_enable_url_download = False
if cfg_enable_url_download:
    url = "https://archive.org/download/yoloTrained/yoloTrained.pt"  # Configure this if you set cfg_enable_url_download to True
    cfg_model_path = f"models/{url.split('/')[-1:][0]}"  # config model path from url name


parser = argparse.ArgumentParser()
parser.add_argument('--weights', nargs='+', type=str, default='best.pt', help='model.pt path(s)')
parser.add_argument('--source', type=str, default='dataset', help='source')  # file/folder, 0 for webcam
parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
parser.add_argument('--conf-thres', type=float, default=0.25, help='object confidence threshold')
parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
parser.add_argument('--view-img', action='store_true', help='display results')
parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
parser.add_argument('--augment', action='store_true', help='augmented inference')
parser.add_argument('--update', action='store_true', help='update all models')
parser.add_argument('--project', default='runs/detect', help='save results to project/name')
parser.add_argument('--name', default='exp', help='save results to project/name')
parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
parser.add_argument('--no-trace', action='store_true', help='don`t trace model')
opt = parser.parse_args()


## END OF CFG


def get_subdirs(b='.'):
    '''
        Returns all sub-directories in a specific Path
    '''
    result = []
    for d in os.listdir(b):
        bd = os.path.join(b, d)
        if os.path.isdir(bd):
            result.append(bd)
    return result


def get_detection_folder():
    '''
        Returns the latest folder in a runs\detect
    '''
    return max(get_subdirs(os.path.join('runs', 'detect')), key=os.path.getmtime)




def imageInput(device, src):
    if src == 'ğŸ“€ä¸Šä¼ è‡ªå·±çš„æ•°æ®':
        image_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡", type=['png', 'jpeg', 'jpg'])
        # col1, col2 = st.columns(2)
        if image_file is not None:
            img = Image.open(image_file)
            with st.container():
                st.image(img, caption='ä¸Šä¼ çš„å›¾ç‰‡', use_column_width='always')
            ts = datetime.timestamp(datetime.now())
            imgpath = os.path.join('dataset/uploads', str(ts) + image_file.name)
            # outputpath = os.path.join('dataset/outputs', os.path.basename(imgpath))
            with open(imgpath, mode="wb") as f:
                f.write(image_file.getbuffer())

            # call Model prediction--
            # model = torch.hub.load('ultralytics/yolov5', 'custom', path='models/yoloTrained.pt', force_reload=True)
            # model.cuda() if device == 'cuda' else model.cpu()
            opt.source = imgpath
            detect(opt)
            outputpath = os.path.join(get_detection_folder(), os.path.basename(imgpath))

            # --Display predicton

            img_ = Image.open(outputpath)
            with st.container():
                st.image(img_, caption='æ£€æµ‹åçš„å›¾ç‰‡', use_column_width='always')

    elif src == 'ğŸ’¿ä»æµ‹è¯•é›†ä¸­é€‰æ‹©':
        # Image selector slider
        imgpath = glob.glob('dataset/images/*')
        imgsel = st.slider('æ»‘åŠ¨æ»‘å—é€‰æ‹©å›¾ç‰‡å§ï¼', min_value=1, max_value=len(imgpath), step=1)
        image_file = imgpath[imgsel - 1]
        submit = st.button("å¼€å§‹æ£€æµ‹ï¼")
        # col1, col2 = st.columns(2, gap='small')
        with st.container():
            img = Image.open(image_file)
            st.image(img, caption='é€‰æ‹©çš„å›¾ç‰‡', use_column_width='always')
        with st.container():
            if image_file is not None and submit:
                # call Model prediction--
                opt.source = image_file
                detect(opt)
                outputpath = os.path.join(get_detection_folder(), os.path.basename(image_file))

                # --Display predicton
                img_ = Image.open(outputpath)
                st.image(img_, caption='æ£€æµ‹åçš„å›¾ç‰‡')
        # detect_info = st.container()
        # with detect_info:
        #     st.write("æ£€æµ‹ä¿¡æ¯ç»Ÿè®¡ï¼š")
        #     st.write("TODO....")



def videoInput(device, src):
    if src == 'ğŸ“€ä¸Šä¼ è‡ªå·±çš„æ•°æ®':
        uploaded_video = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=['mp4', 'mpeg', 'mov'])
        if uploaded_video != None:
            ts = datetime.timestamp(datetime.now())
            imgpath = os.path.join('dataset/uploads', str(ts) + uploaded_video.name)
            # outputpath = os.path.join('dataset/video_output', os.path.basename(imgpath))

            with open(imgpath, mode='wb') as f:
                f.write(uploaded_video.read())  # save video to disk

            st_video = open(imgpath, 'rb')
            video_bytes = st_video.read()
            st.write("ä¸Šä¼ çš„è§†é¢‘:")
            st.video(video_bytes)

            opt.source = imgpath
            with st.spinner('æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨ç­‰...'):
                detect(opt)

            time.sleep(5)
            st.success('å¤„ç†å®Œæˆ!')

            outputpath = os.path.join(get_detection_folder(), os.path.basename(imgpath))
            # print(outputpath)
            st_video2 = open(outputpath, 'rb')
            video_bytes2 = st_video2.read()
            st.write("æ£€æµ‹åçš„è§†é¢‘:")
            st.video(video_bytes2)
    elif src == 'ğŸ’¿ä»æµ‹è¯•é›†ä¸­é€‰æ‹©':
        imgpath = glob.glob('dataset/videos/*')
        imgsel = st.slider('æ»‘åŠ¨æ»‘å—é€‰æ‹©è§†é¢‘å§ï¼', min_value=0, max_value=len(imgpath), step=1)
        image_file = imgpath[imgsel - 1]
        c1, c2 = st.columns(2)
        with c1:
            submit = st.button("å¼€å§‹æ£€æµ‹ï¼")
        with c2:
            if image_file is not None and submit:
                with st.spinner('æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨ç­‰...'):
                    time.sleep(5)
                st.success('å¤„ç†å®Œæˆ!')


        col1, col2 = st.columns(2, gap='small')
        with col1:
            # img = Image.open(image_file)
            st_video = open(image_file, 'rb')
            video_bytes = st_video.read()
            st.write("ä¸Šä¼ çš„è§†é¢‘:")
            st.video(video_bytes)

        with col2:
            if image_file is not None and submit:
                # call Model prediction--
                opt.source = imgpath
                # time.sleep(5)
                outputpath = os.path.join('dataset', 'video_output', 'video0.mp4')
                # print(outputpath)
                st_video2 = open(outputpath, 'rb')
                video_bytes2 = st_video2.read()
                st.write("æ£€æµ‹åçš„è§†é¢‘:")
                st.video(video_bytes2)




def cameraInput(device, src):
    ip_input = st.text_input("è¯·è¾“å…¥æ‘„åƒå¤´IPåœ°å€ï¼")
    ip_button = st.button("è¿æ¥")
    if ip_input != None and ip_button:
        # ä¼ å…¥æ‘„åƒå¤´IPæˆåŠŸæƒ…å†µä¸‹
        st.error('IPæ— æ•ˆï¼', icon="ğŸš¨")


# def webcamInput(device, src):



def showCode():
    st.subheader("ğŸ‘‡æ£€æµ‹å‡½æ•°æºç ï¼š")
    st.markdown(source_code)


def start_detect(authenticator):
    datasrc = st.sidebar.radio("ğŸ’¾é€‰æ‹©è¾“å…¥æº", ['ğŸ’¿ä»æµ‹è¯•é›†ä¸­é€‰æ‹©', 'ğŸ“€ä¸Šä¼ è‡ªå·±çš„æ•°æ®'])
    option = st.sidebar.radio("ğŸ“²é€‰æ‹©è¾“å…¥ç±»å‹", ['ğŸ“·å›¾ç‰‡', 'ğŸ¬è§†é¢‘', 'ğŸ“¹æ‘„åƒå¤´'])
    if torch.cuda.is_available():
        deviceoption = st.sidebar.radio("ğŸ’»é€‰æ‹©è®¡ç®—èµ„æº", ['cpu', 'cuda'], disabled=False, index=1)
    else:
        deviceoption = st.sidebar.radio("ğŸ’»é€‰æ‹©è®¡ç®—èµ„æº", ['cpu', 'cuda'], disabled=True, index=0)


    # -- End of Sidebar

    st.title('ğŸš¢â€œé¹°çœ¼æŠ¤èˆªâ€æ™ºèƒ½èˆ¹èˆ¶æ£€æµ‹ç³»ç»ŸğŸš¢')
    st.markdown('---')
    # st.header('ğŸ‘ˆ é€‰æ‹©å·¦ä¾§åŠŸèƒ½')
    # TODO ä¿®æ”¹
    # st.sidebar.markdown("https://github.com/thepbordin/Obstacle-Detection-for-Blind-people-Deployment")
    if option == "ğŸ“·å›¾ç‰‡":
        imageInput(deviceoption, datasrc)
    elif option == "ğŸ¬è§†é¢‘":
        videoInput(deviceoption, datasrc)
    elif option == "ğŸ“¹æ‘„åƒå¤´":
        cameraInput(deviceoption, datasrc)
    #  elif option == "ğŸŒï¸ç½‘ç»œè§†é¢‘":
    #      webcamInput(deviceoption, datasrc)




def main(authenticator):
    # -- Sidebar
    st.sidebar.title('âš™ï¸é€‰é¡¹')
    st.sidebar.write('ğŸ‘‡è¯·é€‰æ‹©ä¸‹åˆ—åŠŸèƒ½')
    select = st.sidebar.selectbox("ğŸ¥°æƒ³è¦åšç‚¹ä»€ä¹ˆï¼Ÿ", ['å¯åŠ¨æ£€æµ‹ç¨‹åº', 'æŸ¥çœ‹æºä»£ç '])
    # st.sidebar.markdown('---')
    if select == "å¯åŠ¨æ£€æµ‹ç¨‹åº":
        start_detect(authenticator)
    elif select == "æŸ¥çœ‹æºä»£ç ":
        showCode()

    st.sidebar.markdown('---')
    with st.sidebar:
        authenticator.logout('æ³¨é”€', 'main')



if __name__ == '__main__':

    main(opt)


